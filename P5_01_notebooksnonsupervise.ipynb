{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "activated-container",
   "metadata": {},
   "source": [
    "### Réduction des dimenssions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excited-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endless-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 564 ms, sys: 817 ms, total: 1.38 s\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, mallet=False, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Args:\n",
    "  \n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "        model_list : List of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        if mallet == True:\n",
    "            model = gensim.models.wrappers.LdaMallet(mallet_path = mallet_path, \n",
    "                                                     corpus=corpus, num_topics=num_topics, \n",
    "                                                     id2word=id2word, \n",
    "                                                     prefix = 'temp_file_',\n",
    "                                                     workers = 7)\n",
    "        \n",
    "        else:\n",
    "            model = LdaMulticore(corpus=corpus,\n",
    "                                id2word=dictionary,\n",
    "                                num_topics=num_topics, \n",
    "                                random_state=42,\n",
    "                                chunksize=100,\n",
    "                                passes=10,\n",
    "                                workers=7)\n",
    "\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "#model_list, coherence_values = compute_coherence_values(mallet=False, dictionary=id2word, corpus=corpus_tfidf, texts=texts, start=2, limit=51, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "connected-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "# df_topic_sents_keywords = format_topics_sentences(ldamodel=lda, corpus=corpus_tfidf, texts=html_cleaned_texts)\n",
    "\n",
    "# # Format\n",
    "# df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "# df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# # Show\n",
    "# df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-microphone",
   "metadata": {},
   "source": [
    "### Avec bigrammes lematizés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "\n",
    "data = filtered_data['tokenized_post'].values.tolist()\n",
    "\n",
    "bigram = gensim.models.Phrases(data, min_count=1000, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "data_bigrams = [bigram_mod[doc] for doc in data]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "bigrams_data = make_bigrams(data)\n",
    "lemmatized_data = lemmatization(bigrams_data, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "id2word = corpora.Dictionary(lemmatized_data)\n",
    "corpus = [id2word.doc2bow(text) for text in texts] \n",
    "bow_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(mallet=False, dictionary=id2word, corpus=bow_corpus, texts=lemmatized_data, start=2, limit=51, step=1)\n",
    "\n",
    "limit=51; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pprint import pprint\n",
    "optimal_model = model_list[9]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=bow_corpus, texts=html_cleaned_texts)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Publication du premier document\\n\")\n",
    "display(df_dominant_topic.loc[0,'Text'])\n",
    "print(\"\\n\")\n",
    "print(f\"Numéro du topic: {df_dominant_topic.loc[0,'Dominant_Topic']}\")\n",
    "print(\"\\n\")\n",
    "print(\"Mots clés associés\\n\")\n",
    "display(df_dominant_topic.loc[0,'Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sent_topics_sorteddf.iterrows():\n",
    "    print(f\"Numéro du topic: {row['Topic_Num']}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Mots clés associes au topic:\\n\")\n",
    "    print(f\"{row['Keywords']}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Publication la plus significative du topic:\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"{row['Text']}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = sent_topics_sorteddf[[\"Topic_Num\",\"Keywords\"]]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str))\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(optimal_model, bow_corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda.html')\n",
    "display(HTML('lda.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-antibody",
   "metadata": {},
   "source": [
    "## Avec données importées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"./data/cleaned_corpus.csv\")\n",
    "texts = data['Text'].to_list()\n",
    "texts = [tokens.split(\" \") for tokens in texts]\n",
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts] \n",
    "bow_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(mallet=False, dictionary=id2word, corpus=bow_corpus, texts=texts, start=2, limit=51, step=1)\n",
    "\n",
    "limit=51; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-watts",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
